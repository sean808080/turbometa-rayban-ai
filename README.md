# TurboMeta - RayBan Meta Smart Glasses AI Assistant

<div align="center">

![TurboMeta Logo](./rayban.png)

**üåè World's First Full-Chinese AI Multimodal RayBan Meta Assistant**

[![Platform](https://img.shields.io/badge/Platform-iOS%2017.0%2B-blue.svg)](https://www.apple.com/ios/)
[![Swift](https://img.shields.io/badge/Swift-5.0-orange.svg)](https://swift.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Release](https://img.shields.io/github/v/release/Turbo1123/turbometa-rayban-ai)](https://github.com/Turbo1123/turbometa-rayban-ai/releases)

[English](./README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README_CN.md)

</div>

## üì• Download

> **No App Store submission** - Self-sign and install using tools below

| Version | Download | Size |
|---------|----------|------|
| v1.0.0 | [**TurboMeta_unsigned.ipa**](https://github.com/Turbo1123/turbometa-rayban-ai/releases/download/v1.0.0/TurboMeta_unsigned.ipa) | 6.0 MB |

### Installation Methods

| Tool | Platform | Description |
|------|----------|-------------|
| [AltStore](https://altstore.io/) | macOS/Windows | Free, requires Apple ID |
| [Sideloadly](https://sideloadly.io/) | macOS/Windows | Free, easy to use |
| [Áà±ÊÄùÂä©Êâã](https://www.i4.cn/) | Windows | Chinese users recommended |
| Xcode | macOS | Build from source code |

### Quick Install Steps
1. Download `TurboMeta_unsigned.ipa` from above
2. Open your preferred signing tool
3. Connect iPhone and sign/install the IPA
4. Trust developer in **Settings ‚Üí General ‚Üí VPN & Device Management**
5. Open TurboMeta and configure your API Key

## üìñ Introduction

TurboMeta is a full-featured multimodal AI assistant built exclusively for RayBan Meta smart glasses, powered by Alibaba Cloud's Qwen multimodal AI models:

- üéØ **Live AI Conversations**: Real-time multimodal interaction through glasses camera and microphone
- üçé **Smart Nutrition Analysis**: Capture food photos and get detailed nutritional information and health recommendations
- üëÅÔ∏è **Image Recognition**: Intelligently identify objects, scenes, and text in your field of view
- üé• **Live Streaming**: Stream directly to platforms like Douyin, Kuaishou, and Xiaohongshu
- üåê **Full Chinese Support**: Complete Chinese AI interaction experience, perfectly tailored for Chinese users

This is the world's first **fully Chinese-enabled** RayBan Meta AI assistant, bringing the convenience of smart glasses to Chinese-speaking users.

## ‚ú® Core Features

### ü§ñ Live AI - Real-time Conversations
- **Multimodal Interaction**: Simultaneous voice and visual input support
- **Real-time Response**: Based on Qwen Omni-Realtime model with low-latency voice conversations
- **Scene Understanding**: AI can see what's in front of you and provide relevant suggestions
- **Natural Responses**: Smooth and natural Chinese conversation experience
- **One-tap Hide**: Support for hiding conversation interface to focus on visual experience

### üçΩÔ∏è LeanEat - Smart Nutrition Analysis
- **Food Recognition**: Identify food types by taking photos
- **Nutritional Content**: Detailed data on calories, protein, fat, carbohydrates, etc.
- **Health Scoring**: Health scoring system from 0-100
- **Nutrition Advice**: Personalized nutritional recommendations from AI
- **Beautiful Interface**: Carefully designed UI with clear nutritional information display

### üì∏ Real-time Photography
- **Auto-start**: Automatically connects to glasses and starts preview when opened
- **Multi-function Integration**: Choose nutrition analysis or AI recognition after taking photos
- **Smooth Experience**: Real-time video stream preview

### üé• Live Streaming
- **Platform Support**: Compatible with mainstream live streaming platforms
- **Clean Interface**: Pure view focused on streaming content

## üõ†Ô∏è Tech Stack

- **Platform**: iOS 17.0+
- **Language**: Swift 5.0 + SwiftUI
- **SDK**: Meta Wearables DAT SDK v0.3.0
- **AI Models**:
  - Qwen Omni-Realtime: Real-time multimodal conversations
  - Qwen VL-Plus: Visual understanding and image analysis
- **Architecture**: MVVM + Combine
- **Audio**: AVAudioEngine + AVAudioPlayerNode

## üìã Requirements

### Hardware Requirements
- ‚úÖ RayBan Meta Smart Glasses (Stories or latest model)
- ‚úÖ iPhone (iOS 17.0 or higher)
- ‚úÖ Stable internet connection

### Software Requirements
- ‚úÖ Xcode 15.0 or higher
- ‚úÖ Meta View App (for pairing glasses)
- ‚úÖ Alibaba Cloud account (for API access)

### API Requirements
You need to apply for the following Alibaba Cloud APIs:
1. **Qwen Omni-Realtime API**: For real-time conversations
2. **Qwen VL-Plus API**: For image recognition and nutrition analysis

üëâ [Apply for APIs at Alibaba Cloud](https://dashscope.aliyun.com/)

## üöÄ Installation Guide

### Step 1: Enable RayBan Meta Developer Mode

‚ö†Ô∏è **Important**: Since this is currently in Preview phase, you must enable developer mode to use it.

1. Open **Meta View App** (or **Meta AI App**) on your iPhone
2. Go to **Settings** ‚Üí **App Info** or **About**
3. Find **Version Number**
4. **Tap the version number 5 times consecutively**
5. You'll see a "Developer mode enabled" message

### Step 2: Configure API Key

1. Go to [Alibaba Cloud DashScope](https://dashscope.aliyun.com/)
2. Log in and create an API Key
3. Open `VisionAPIConfig.swift` in the project
4. Replace with your API Key:

```swift
struct VisionAPIConfig {
    static let apiKey = "sk-YOUR-API-KEY-HERE"
}
```

### Step 3: Build the Project

1. Open `CameraAccess.xcodeproj` with Xcode
2. Select your development team (Team)
3. Modify Bundle Identifier (if needed)
4. Connect your iPhone
5. Click **Run** or press `Cmd + R`

### Step 4: Signing and Installation

#### Method A: Direct Installation with Xcode (Recommended)
1. Select your iPhone device in Xcode
2. Click the Run button
3. First-time run requires trusting the developer in iPhone Settings

#### Method B: Export IPA and Self-Sign
1. In Xcode, select **Product** ‚Üí **Archive**
2. Export the IPA file
3. Use AltStore, Sideloadly, or other tools to sign and install

```bash
# Using ios-deploy (requires installation)
brew install ios-deploy
ios-deploy --bundle YourApp.app
```

### Step 5: Pair Your Glasses

1. Open Meta View App
2. Pair your RayBan Meta glasses
3. Ensure Bluetooth is enabled
4. Return to TurboMeta App and wait for connection success

## üì± Usage Guide

### First-time Use

1. Launch TurboMeta App
2. Ensure RayBan Meta glasses are paired and turned on
3. Wait for device connection (status shown at top)
4. Select the feature you want to use

### Live AI Real-time Conversations

1. Tap the **Live AI** card on the home screen
2. Wait for connection success (green dot in upper right)
3. Start speaking, AI will respond in real-time
4. AI can see what's in front of you
5. Tap the üëÅÔ∏è button to hide conversation history

**Tips**:
- Speak clearly and maintain appropriate distance
- Ask "What do you see?" to have AI describe the scene
- AI responds in concise Chinese

### LeanEat Nutrition Analysis

1. Tap the **LeanEat** card on the home screen
2. Point at food and tap the camera button üì∑
3. In photo preview, tap **Nutrition Analysis**
4. Wait for AI analysis to complete
5. View nutritional content, health score, and recommendations

**Use Cases**:
- Take photos before meals to understand nutritional content
- Track daily intake when on a fitness diet
- Learn about food nutrition

### Live Streaming

1. Tap the **Live Stream** card on the home screen
2. Wait for video stream to start
3. Create your streaming content
4. Tap stop button to end the stream

## üé® Interface Preview

<table>
  <tr>
    <td><b>Home</b></td>
    <td><b>Live AI</b></td>
    <td><b>Nutrition Analysis</b></td>
  </tr>
  <tr>
    <td><img src="./screenshots/home.png" width="200"/></td>
    <td><img src="./screenshots/liveai.png" width="200"/></td>
    <td><img src="./screenshots/nutrition.png" width="200"/></td>
  </tr>
</table>

## ‚öôÔ∏è Configuration Options

### API Configuration

Configure in `VisionAPIConfig.swift`:

```swift
struct VisionAPIConfig {
    // Alibaba Cloud API Key
    static let apiKey = "sk-YOUR-API-KEY-HERE"

    // API Base URL (usually doesn't need modification)
    static let baseURL = "https://dashscope.aliyuncs.com"
}
```

### System Prompts

Customize AI response style in `OmniRealtimeService.swift`:

```swift
"instructions": "You are a RayBan Meta smart glasses AI assistant. Keep answers concise and conversational..."
```

## üîß Troubleshooting

### Q1: Glasses won't connect?

**Solutions**:
1. Ensure glasses are successfully paired in Meta View App
2. Check if Bluetooth is enabled
3. Restart TurboMeta App
4. Restart glasses (place in charging case)
5. Ensure developer mode is enabled

### Q2: AI not responding or responding slowly?

**Solutions**:
1. Check if internet connection is stable
2. Verify API Key is correctly configured
3. Check if Alibaba Cloud API quota is sufficient
4. Review console logs for errors

### Q3: Nutrition analysis results inaccurate?

**Solutions**:
1. Ensure food photos are clear
2. Take photos in good lighting
3. Show food completely in frame
4. AI analysis is for reference only, not a substitute for professional nutritionists

### Q4: Cannot install on phone?

**Solutions**:
1. Check if iPhone is in trusted devices list
2. Verify developer certificate is valid
3. Modify Bundle Identifier to avoid conflicts
4. Free Apple Developer accounts require re-signing every 7 days

### Q5: Voice recognition inaccurate?

**Solutions**:
1. Ensure environment is relatively quiet
2. Speak clearly at moderate speed
3. Don't obstruct the microphone
4. Currently optimized for Chinese, other languages may be less accurate

## üîí Privacy and Security

- ‚úÖ All audio/video data is only used for AI processing
- ‚úÖ No storage or upload of user privacy data
- ‚úÖ API communications use HTTPS encryption
- ‚úÖ Images and voice are retained only during session
- ‚úÖ Complies with Apple and Meta privacy policies

## üó∫Ô∏è Roadmap

### ‚úÖ Completed
- [x] Live AI real-time conversations
- [x] LeanEat nutrition analysis
- [x] Image recognition
- [x] Basic live streaming functionality
- [x] Bilingual Chinese/English support
- [x] Conversation history saving
- [x] One-tap hide conversations

### üöß In Progress
- [ ] Improve multilingual support
- [ ] Optimize UI/UX
- [ ] Performance optimization

### üìÖ Planned
- [ ] Real-time translation feature
- [ ] WordLearn vocabulary learning
- [ ] Cloud conversation sync
- [ ] More live streaming platform support
- [ ] Offline mode
- [ ] Apple Watch companion app

## ü§ù Contributing

Contributions, bug reports, and feature suggestions are welcome!

1. Fork this project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìÑ License

This project is based on modifications of original code from Meta Platforms, Inc. and follows the original project's license.

Some code copyright belongs to Meta Platforms, Inc. and its affiliates.

Please see [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Meta Platforms, Inc.** - For providing DAT SDK and original sample code
- **Alibaba Cloud Qwen Team** - For powerful multimodal AI capabilities
- **RayBan** - For excellent smart glasses hardware

## üöÄ How to Open Source This Project

### 1. Create GitHub Repository

```bash
# Create a new repository on GitHub website
# Then execute in your project directory:
git init
git add .
git commit -m "Initial commit: TurboMeta - RayBan Meta AI Assistant"
git branch -M main
git remote add origin https://github.com/your-username/your-repo.git
git push -u origin main
```

### 2. Protect Sensitive Information

‚úÖ **Security Measures Implemented**:
- API Keys are no longer hardcoded in the source code
- Uses iOS Keychain for secure storage of user API Keys
- Users configure their own API Keys in the App Settings

‚ö†Ô∏è **Pre-release Checklist**:
```bash
# Search for potential sensitive information
grep -r "sk-" .
grep -r "API" . | grep -i "key"
```

### 3. Add .gitignore File

Create a `.gitignore` file in project root:

```gitignore
# Xcode
build/
*.pbxuser
*.mode1v3
*.mode2v3
*.perspectivev3
xcuserdata/
*.xccheckout
*.moved-aside
DerivedData/
*.hmap
*.ipa
*.xcuserstate
*.xcworkspace

# API Keys (extra protection)
**/*APIKey*.swift
**/APIKeys.swift
**/*Secret*.swift

# macOS
.DS_Store
```

### 4. Choose Open Source License

This project is based on Meta DAT SDK sample code and follows the original project's license. You can:
- Keep the same license as Meta's original project
- Choose MIT, Apache 2.0, or other permissive licenses for your code
- Acknowledge the original source code in the LICENSE file

### 5. User Configuration Instructions

‚ö†Ô∏è **Important Notice**: Users of this project need to:

1. **Apply for API Key**: Visit [Alibaba Cloud DashScope](https://dashscope.aliyun.com/)
2. **Configure API Key**: Enter in App Settings ‚Üí API Key Management
3. **API Key Security**: Stored securely in iOS Keychain, never exposed

## üåü If This Project Helps You

- ‚≠êÔ∏è Star the project
- üêõ Report bugs or suggest features
- üîÄ Fork and contribute code
- üì¢ Share with others

---

<div align="center">

**Making Smart Glasses Speak Chinese üá®üá≥**

Made with ‚ù§Ô∏è for RayBan Meta Users

</div>
